{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment 1 - Regression and Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HA1-DatasetScaled.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.1737</td>\n",
       "      <td>-2.5469</td>\n",
       "      <td>-1.8316</td>\n",
       "      <td>-1.9110</td>\n",
       "      <td>-1.2742</td>\n",
       "      <td>-3.2043</td>\n",
       "      <td>-2.6712</td>\n",
       "      <td>-2.1218</td>\n",
       "      <td>-1.2523</td>\n",
       "      <td>-2.2206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>-3.3123</td>\n",
       "      <td>-2.7858</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>-1.5235</td>\n",
       "      <td>-1.7297</td>\n",
       "      <td>-1.4782</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.1737</td>\n",
       "      <td>-2.5469</td>\n",
       "      <td>-1.8316</td>\n",
       "      <td>-1.9110</td>\n",
       "      <td>-1.2742</td>\n",
       "      <td>-3.2043</td>\n",
       "      <td>-2.6712</td>\n",
       "      <td>-2.1218</td>\n",
       "      <td>-1.2523</td>\n",
       "      <td>-2.2206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>-3.3123</td>\n",
       "      <td>-2.7858</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>-1.5235</td>\n",
       "      <td>-1.7297</td>\n",
       "      <td>-1.4782</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.1737</td>\n",
       "      <td>-2.5469</td>\n",
       "      <td>-1.8316</td>\n",
       "      <td>-1.9110</td>\n",
       "      <td>-1.2742</td>\n",
       "      <td>-3.2043</td>\n",
       "      <td>-2.6712</td>\n",
       "      <td>-2.1218</td>\n",
       "      <td>-1.2523</td>\n",
       "      <td>-2.2206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>-3.3123</td>\n",
       "      <td>-2.7858</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>-1.5235</td>\n",
       "      <td>-1.7297</td>\n",
       "      <td>-1.4782</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.1737</td>\n",
       "      <td>-2.5469</td>\n",
       "      <td>-1.8316</td>\n",
       "      <td>-1.9110</td>\n",
       "      <td>-1.2742</td>\n",
       "      <td>-3.2043</td>\n",
       "      <td>-2.6712</td>\n",
       "      <td>-2.1218</td>\n",
       "      <td>-1.2523</td>\n",
       "      <td>-2.2206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>-3.3123</td>\n",
       "      <td>-2.7858</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>-1.5235</td>\n",
       "      <td>-1.7297</td>\n",
       "      <td>-1.4782</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.1737</td>\n",
       "      <td>-1.5994</td>\n",
       "      <td>-0.9850</td>\n",
       "      <td>-1.0041</td>\n",
       "      <td>-0.5006</td>\n",
       "      <td>-3.2043</td>\n",
       "      <td>-2.6712</td>\n",
       "      <td>-2.1218</td>\n",
       "      <td>-1.2523</td>\n",
       "      <td>-2.2206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9684</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>-0.8995</td>\n",
       "      <td>-3.3123</td>\n",
       "      <td>-2.7858</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>-1.5235</td>\n",
       "      <td>-1.7297</td>\n",
       "      <td>-1.4782</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0             -2.1737           -2.5469               -1.8316   \n",
       "1             -2.1737           -2.5469               -1.8316   \n",
       "2             -2.1737           -2.5469               -1.8316   \n",
       "3             -2.1737           -2.5469               -1.8316   \n",
       "4             -2.1737           -1.5994               -0.9850   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0            -1.9110                -1.2742              -3.2043   \n",
       "1            -1.9110                -1.2742              -3.2043   \n",
       "2            -1.9110                -1.2742              -3.2043   \n",
       "3            -1.9110                -1.2742              -3.2043   \n",
       "4            -1.0041                -0.5006              -3.2043   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                  -2.6712            -2.1218                -1.2523   \n",
       "1                  -2.6712            -2.1218                -1.2523   \n",
       "2                  -2.6712            -2.1218                -1.2523   \n",
       "3                  -2.6712            -2.1218                -1.2523   \n",
       "4                  -2.6712            -2.1218                -1.2523   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
       "0          -2.2206  ...            0.7124         0.9014             0.8055   \n",
       "1          -2.2206  ...            0.7124         0.9014             0.8055   \n",
       "2          -2.2206  ...            0.7124         0.9014             0.8055   \n",
       "3          -2.2206  ...            0.7124         0.9014             0.8055   \n",
       "4          -2.2206  ...           -0.9684        -1.0090            -0.8995   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
       "0          -3.3123              -2.7858        -1.6406            -1.5235   \n",
       "1          -3.3123              -2.7858        -1.6406            -1.5235   \n",
       "2          -3.3123              -2.7858        -1.6406            -1.5235   \n",
       "3          -3.3123              -2.7858        -1.6406            -1.5235   \n",
       "4          -3.3123              -2.7858        -1.6406            -1.5235   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0      -1.7297          -1.4782           52.0  \n",
       "1      -1.7297          -1.4782           50.0  \n",
       "2      -1.7297          -1.4782           41.5  \n",
       "3      -1.7297          -1.4782           32.0  \n",
       "4      -1.7297          -1.4782           29.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check if any column has a missing value overall (not per row)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.drop('critical_temp', axis=1), df['critical_temp'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# X_train, y_train: Training data\n",
    "# X_test, y_test: Test data\n",
    "# X_val, y_val: Validation data (IVS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objective 1** - Produce the best regression model for critical_temp (Dependent Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1: Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model perform GridSearch on testing set to establish the best hyperparameters `min_sample_leaf` and `max_depth`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data for GridSearchCV\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# Create an array of indices:\n",
    "# -1 indicates the sample is part of the training set\n",
    "# 0 indicates the sample is part of the test set (used for evaluation during GridSearch)\n",
    "test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "# Define the regressor\n",
    "dtree_regressor = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\n",
    "    'max_depth': np.arange(2, 7),\n",
    "    'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "    'min_samples_leaf': [5, 10, 20, 25]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "gridCV = GridSearchCV(dtree_regressor, parameters, scoring=scorer, cv=ps)\n",
    "gridCV.fit(X_combined, y_combined)\n",
    "dtree_regressor_best = gridCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the results as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max Depth     Criterion  Min Samples Leaf         MSE\n",
      "36          6  friedman_mse                 5  234.917985\n",
      "37          6  friedman_mse                10  235.591654\n",
      "39          6  friedman_mse                25  236.868860\n",
      "38          6  friedman_mse                20  237.029590\n",
      "33          5  friedman_mse                10  262.263776\n"
     ]
    }
   ],
   "source": [
    "results = gridCV.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Extract each hyperparameter into its own column from the 'params' column\n",
    "df_results['max_depth'] = df_results['params'].apply(lambda x: x['max_depth'])\n",
    "df_results['criterion'] = df_results['params'].apply(lambda x: x['criterion'])\n",
    "df_results['min_samples_leaf'] = df_results['params'].apply(lambda x: x['min_samples_leaf'])\n",
    "\n",
    "# Select relevant columns and create the desired dataframe\n",
    "df_mse = df_results[['max_depth', 'criterion', 'min_samples_leaf', 'mean_test_score']]\n",
    "df_mse['mean_test_score'] = -df_mse['mean_test_score']  # Convert negative MSE to positive\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_mse.columns = ['Max Depth', 'Criterion', 'Min Samples Leaf', 'MSE']\n",
    "\n",
    "# Drop rows where 'Mean MSE' is NaN\n",
    "df_mse = df_mse.dropna(subset=['MSE'])\n",
    "\n",
    "# Display the dataframe\n",
    "df_mse_sorted = df_mse.sort_values(by='MSE')\n",
    "df_mse_head = df_mse_sorted.head(5)\n",
    "print(df_mse_head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of the GridSearch the best `max_depth` is 6 levels and the best `min_sample_leaf` is 10 samples per leaf. Now let's look at the metrics of the chosen model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on Testing Set: 218.04258196819833\n",
      "Root Mean Squared Error (RMSE) on Testing Set: 14.766264997222498\n",
      "Mean Absolute Error (MAE) on Testing Set: 9.733272914639297\n",
      "R-squared on Testing Set: 0.8142430436878382\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testing set\n",
    "y_pred_test = dtree_regressor_best.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Squared Error (MSE) on Testing Set: {mse_test}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on Testing Set: {rmse_test}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Testing Set: {mae_test}\")\n",
    "print(f\"R-squared on Testing Set: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2: Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LINEAR REGRESSION MODEL #\n",
    "reg1 = LinearRegression().fit(X_train, y_train)\n",
    "y_pred1_test = reg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. RIDGE REGRESSION MODEL WITH CROSS-VALIDATION (K-Fold Cross Validation) #\n",
    "\n",
    "reg2 = RidgeCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X_train, y_train) # ridge regression with cross-validation and range of alpha values 0.001, 0.01, 0.1, 1\n",
    "y_pred2_test = reg2.predict(X_test)\n",
    "reg2_best_alpha = reg2.alpha_ # Resulting best alpha from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LASSO REGRESSION MODEL WITH CROSS-VALIDATION (K-Fold Cross Validation) #\n",
    "\n",
    "reg3 = LassoCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1], max_iter=10000).fit(X_train, y_train) # lasso regression with cross-validation and range of alpha values 0.001, 0.01, 0.1, 1\n",
    "y_pred3_test = reg3.predict(X_test)\n",
    "reg3_best_alpha = reg3.alpha_ # Resulting best alpha from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LASSO REGRESSION MODEL WITH CROSS-VALIDATION (K-Fold Cross Validation) - With Normalised Features #\n",
    "\n",
    "# Compute statistics from the training set\n",
    "mean_train = X_train.mean()\n",
    "max_min_range_train = X_train.max() - X_train.min()\n",
    "# Normalize the training set\n",
    "X_train_norm = (X_train - mean_train) / max_min_range_train\n",
    "# Normalize the test set using the same statistics from the training set\n",
    "X_test_norm = (X_test - mean_train) / max_min_range_train\n",
    "\n",
    "reg4 = LassoCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1], max_iter=10000).fit(X_train_norm, y_train) # lasso regression with cross-validation and range of alpha values 0.001, 0.01, 0.1, 1\n",
    "y_pred4_test = reg4.predict(X_test_norm)\n",
    "reg4_best_alpha = reg4.alpha_ # Resulting best alpha from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ELASTIC NET REGRESSION MODEL WiTH CROSS-VALIDATION (K-Fold Cross Validation) #\n",
    "\n",
    "# Train model\n",
    "reg5 = ElasticNetCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1], l1_ratio=[.1, .5, .7, .9, .95, .99, 1], max_iter=10000).fit(X_train, y_train) # elastic net regression with cross-validation and range of alpha values 0.001, 0.01, 0.1, 1 as well as range of l1_ratio values 0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1\n",
    "y_pred5_test = reg5.predict(X_test)\n",
    "reg5_best_alpha = reg5.alpha_  # Resulting best alpha from cross-validation\n",
    "reg5_best_l1_ratio = reg5.l1_ratio_ # Resulting best l1_ratio from cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: The warnings above are the result of models not being able to converge. This is due to the fact that several models with different hyperparameters were tested and for some of the parameters the model did not converge. The models that did not converge were not used in the final model selection.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Models: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best l1_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>311.754275</td>\n",
       "      <td>17.656565</td>\n",
       "      <td>13.277266</td>\n",
       "      <td>0.734407</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>311.750602</td>\n",
       "      <td>17.656461</td>\n",
       "      <td>13.277173</td>\n",
       "      <td>0.734410</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>311.898822</td>\n",
       "      <td>17.660657</td>\n",
       "      <td>13.274335</td>\n",
       "      <td>0.734284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression (Normalised)</td>\n",
       "      <td>313.654581</td>\n",
       "      <td>17.710296</td>\n",
       "      <td>13.314416</td>\n",
       "      <td>0.732788</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet Regression</td>\n",
       "      <td>311.898822</td>\n",
       "      <td>17.660657</td>\n",
       "      <td>13.274335</td>\n",
       "      <td>0.734284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model         MSE       RMSE        MAE        R2  \\\n",
       "0              Linear Regression  311.754275  17.656565  13.277266  0.734407   \n",
       "1               Ridge Regression  311.750602  17.656461  13.277173  0.734410   \n",
       "2               Lasso Regression  311.898822  17.660657  13.274335  0.734284   \n",
       "3  Lasso Regression (Normalised)  313.654581  17.710296  13.314416  0.732788   \n",
       "4          ElasticNet Regression  311.898822  17.660657  13.274335  0.734284   \n",
       "\n",
       "  Best Alpha Best l1_ratio  \n",
       "0          -             -  \n",
       "1       0.01             -  \n",
       "2      0.001             -  \n",
       "3      0.001             -  \n",
       "4      0.001           1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'MAE', 'R2', 'Best Alpha', 'Best l1_ratio'])\n",
    "# Create data frames for each model\n",
    "model1 = pd.DataFrame({'Model': 'Linear Regression', 'MSE': mean_squared_error(y_test, y_pred1_test), 'RMSE': np.sqrt(mean_squared_error(y_test, y_pred1_test)), 'MAE': mean_absolute_error(y_test, y_pred1_test), 'R2': r2_score(y_test, y_pred1_test), 'Best Alpha': '-', 'Best l1_ratio': '-'}, index=[0])\n",
    "model2 = pd.DataFrame({'Model': 'Ridge Regression', 'MSE': mean_squared_error(y_test, y_pred2_test), 'RMSE': np.sqrt(mean_squared_error(y_test, y_pred2_test)), 'MAE': mean_absolute_error(y_test, y_pred2_test), 'R2': r2_score(y_test, y_pred2_test), 'Best Alpha': reg2_best_alpha, 'Best l1_ratio': '-'}, index=[1])\n",
    "model3 = pd.DataFrame({'Model': 'Lasso Regression', 'MSE': mean_squared_error(y_test, y_pred3_test), 'RMSE': np.sqrt(mean_squared_error(y_test, y_pred3_test)), 'MAE': mean_absolute_error(y_test, y_pred3_test), 'R2': r2_score(y_test, y_pred3_test), 'Best Alpha': reg3_best_alpha, 'Best l1_ratio': '-'}, index=[2])\n",
    "model4 = pd.DataFrame({'Model': 'Lasso Regression (Normalised)', 'MSE': mean_squared_error(y_test, y_pred4_test), 'RMSE': np.sqrt(mean_squared_error(y_test, y_pred4_test)), 'MAE': mean_absolute_error(y_test, y_pred4_test), 'R2': r2_score(y_test, y_pred4_test), 'Best Alpha': reg4_best_alpha, 'Best l1_ratio': '-'}, index=[3])\n",
    "model5 = pd.DataFrame({'Model': 'ElasticNet Regression', 'MSE': mean_squared_error(y_test, y_pred5_test), 'RMSE': np.sqrt(mean_squared_error(y_test, y_pred5_test)), 'MAE': mean_absolute_error(y_test, y_pred5_test), 'R2': r2_score(y_test, y_pred5_test), 'Best Alpha': reg5_best_alpha, 'Best l1_ratio': reg5_best_l1_ratio}, index=[4])\n",
    "# Concatenate the data frames\n",
    "df_results = pd.concat([df_results, model1, model2, model3, model4, model5], ignore_index=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESSION MODEL SELECTION:\n",
    "The Decision Tree Regression has lower error metrics (MSE, RMSE, and MAE), indicating more accurate predictions, and a higher R-squared (R2), suggesting a better fit to the data, making it a superior model. Therefore, we decided to go with the Decision Tree Regression model. Let's now test the model on independent validation set (IVS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Set</th>\n",
       "      <th>Testing Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>228.772711</td>\n",
       "      <td>218.042582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>15.125234</td>\n",
       "      <td>14.766265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>9.944892</td>\n",
       "      <td>9.733273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.808855</td>\n",
       "      <td>0.814243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Validation Set  Testing Set\n",
       "MSE            228.772711   218.042582\n",
       "RMSE            15.125234    14.766265\n",
       "MAE              9.944892     9.733273\n",
       "R-squared        0.808855     0.814243"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on validation set - Decision Tree\n",
    "y_pred_val = dtree_regressor_best.predict(X_val)\n",
    "# Define metrics for validation set\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "# Calculate metrics for validation set\n",
    "metrics_val = {\n",
    "    \"Validation Set\": [mse_val, rmse_val, mae_val, r2_val]\n",
    "}\n",
    "# Calculate metrics for testing set\n",
    "metrics_test = {\n",
    "    \"Testing Set\": [mse_test, rmse_test, mae_test, r2_test]\n",
    "}\n",
    "# Create DataFrames\n",
    "df_metrics_val = pd.DataFrame(metrics_val, index=[\"MSE\", \"RMSE\", \"MAE\", \"R-squared\"])\n",
    "df_metrics_test = pd.DataFrame(metrics_test, index=[\"MSE\", \"RMSE\", \"MAE\", \"R-squared\"])\n",
    "# Combine the DataFrames for validation and testing metrics\n",
    "df_metrics = pd.concat([df_metrics_val, df_metrics_test], axis=1)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CONCUSION:*** The metrics on the validation set are reasonably close to those on the test set which suggests that our model is performing consistently and is likely to generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objective 2** - Produce the best binary classification model assuming as positive all instances with values of critical_temp >= 80.0 and as negatives all remaining cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Firstly, we need to transform all the target columns to the binary classification problem instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# transform the target column to a binary classification problem: 0 - negative, 1 - positive\n",
    "def transform_to_binary(x):\n",
    "    return 1 if x >= 80 else 0\n",
    "\n",
    "y_train_bin = y_train.apply(transform_to_binary)\n",
    "y_val_bin = y_val.apply(transform_to_binary)\n",
    "y_test_bin = y_test.apply(transform_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11327\n",
       "1     2224\n",
       "Name: critical_temp, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can see that the data is imbalanced, we have much more negative (0) observations. Therefore, we will use `F1 score` as our main metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 2.1 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_classification_scores(y_true, y_predicted):\n",
    "    return pd.DataFrame([\n",
    "        ['Accuracy', round(accuracy_score(y_true, y_predicted), 4)],\n",
    "        ['Precision', round(precision_score(y_true, y_predicted), 4)],\n",
    "        ['Recall', round(recall_score(y_true, y_predicted), 4)],\n",
    "        ['F1 score', round(f1_score(y_true, y_predicted), 4)]\n",
    "    ], columns=['metric', 'score'])\n",
    "\n",
    "def print_confusion_matrix(y_true, y_predicted):\n",
    "    print(\"The Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(y_true, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We will explore different values of the following hyperparameters: `min_samples_leaf`, `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.794275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0.782453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.780357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.779783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_samples_leaf  max_depth        F1\n",
       "456                 2         40  0.794275\n",
       "504                 2         44  0.782453\n",
       "314                 6         28  0.780357\n",
       "408                 2         36  0.780142\n",
       "288                 2         26  0.779783"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_samples_leaf_values = range(2,50,2)\n",
    "max_depth_values = range(2,50,2)\n",
    "\n",
    "results = {\"min_samples_leaf\": [], \"max_depth\": [], \"F1\": []}\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for min_samples_leaf in min_samples_leaf_values:\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        model.fit(X_train, y_train_bin)\n",
    "        y_preds = model.predict(X_test)\n",
    "        f1 = f1_score(y_test_bin, y_preds)\n",
    "\n",
    "        results[\"min_samples_leaf\"].append(min_samples_leaf)\n",
    "        results[\"max_depth\"].append(max_depth)\n",
    "        results[\"F1\"].append(f1)\n",
    "\n",
    "scores_df = pd.DataFrame(results, index=None)\n",
    "scores_df = scores_df.sort_values(by=\"F1\", ascending=False)\n",
    "\n",
    "best_max_depth = int(scores_df.iloc[0].max_depth)\n",
    "best_min_samples_leaf = int(scores_df.iloc[0].min_samples_leaf)\n",
    "\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Model with `max_depth`=6 And `min_samples_leaf`=24 turned out to be the best. However, if we look at the table below showing 5 best performing hyperparameters combinations, we can make a few interesting observations. \n",
    "The F1 scores for all those models are very similar and `min_samples_leaf`=6 seems to be a very stable value. However, when it comes to `max_depth`, we donâ€™t see one definite value. There is quite a big variation in this value among the models.\n",
    "Therefore, we decided to investigate `max_depth` value deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGwCAYAAABCV9SaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhL0lEQVR4nO3dd3wUdf4/8NdszW56T0gCoRNagCAY7AoE8ThA7ycHKAEVTyUnmrPAVwXBk1gRCyc24PT04M7DdnBADE0B6SA19BRI78mmbJnfH5NsElJMyO7OJvt6Ph5LdmdnZ9+7nw37ymc+8xlBFEURRERERF2cQu4CiIiIiByBoYeIiIhcAkMPERERuQSGHiIiInIJDD1ERETkEhh6iIiIyCUw9BAREZFLUMldgKNZLBZcvXoVnp6eEARB7nKIiIioDURRRFlZGbp16waF4vr6bFwu9Fy9ehURERFyl0FERETXISMjA+Hh4df1WJcLPZ6engCkN02n02Hr1q0YP3481Gq1zJW5LqPRyHZwAmwH58B2cA5sB+fQsB0qKysRERFh/R6/Hi4Xeup2aXl5eUGn00Gv18PLy4sfahkZjUa2gxNgOzgHtoNzYDs4h+baoSNDUziQmYiIiFwCQw8RERG5BIYeIiIicgkMPUREROQSGHqIiIjIJTD0EBERkUtg6CEiIiKXwNBDRERELoGhh4iIiFwCQw8RERG5BIYeIiIicgkMPUREROQSXO6Eo0RE10sURRjNIkwWi/TTbIHJIsJkESEAUCoEKAQBSoUApSBAoQBUCgUUCkBZu7wjJ0skoo5h6CHqxIoqalBebUK1yYwqowXVJguqTWbpp7HBdZMF1cYG103m2vvr16mqMeFqtgIb8g9DqVRAIQCAAIUAKGq/wAUIEGpvN/wpNFhPEKSzICsEwCICZosUDCy14cB8zU9puaXxcrMIi9hwPQssFuk1KxS19TSooe65gfpapfsb1F9bl1C7jgjpeYyW2vBiFmG0SD9NZgtqasONySzCWBtuzBaxw20mCPUBqD4cCQ0CE1BdpcTrp3ZZA5L0ntY+vrYNpOv1Z5wWrP80XS4CsIgiRFH6aRFFWCwNrotSoLPU3m+2XLPuNffXbV8h1Ndj/TzUvr9o9Plo/NloeFtxzWus+yzVrYcG2xUaPV+DZQ3WkT5zorV26Xr967LU3jaLddfr17n2caKoxNO/bLV+3qRaGr/Ohp/3us+ccM16QoPfH+tnteHnspnfK+t70Mp61xKb+XiKaLqwufWA5n936l/nNf8X1L4nLa3TI0CPJ27v0/wTyYihh6iTqDKacfJqKY6kF+FoRjGOpBfjSnGljZ9FgdPF+TbeZtemEKTeHABSOPuNXCSKgKk20LVMQHFNle2KtDERAEQR5vpbXZRgDX9d+3XaXkwPX4YeImobURSRWVSJw+lFOJJejCMZxTh1tQRGc9P/ePUaJbQqBbQqJbRqRf11laL2dt39ra+jEkScOnEcQ4YOhUKptP5lX/efvtjMX/wAGvQE1K8n1v4lrRQEKJWCtWdDpRCgVCqkn7W9HCplg/sU0n0K6+36n3U9As31PDTsxbj2p+Wa+uvuAwC1UoBKoYBKKUBdW5dKqbAuVyul2ypF7f1KAera9euuKxSN/+Suex5zg16Eul4Fs6X+ttTrgPrrtT+ra4z46eefMWbMTVCpVBBrtylatw/UfQGLImrvr3/uhuuJkFaw/gWuqO9BUAjS+y8Ijf/Cr7tf2bA3TSE06rmQ2kHafl1biGL9czZsH6CuLWrvs0g/xYafmQa1172+us9U3XJL7YutW+fax6F2maKu56zBa1YqGvb41X+e6nY7KhT170fd+2Axm7Bt2zbceeedUKnUjT5nDZ+/4Wf+2s9jw/WkXsLG6137+hq+l40+yw0+Vw174JrbVdrcztPmeoWEa9YU0fLvDsSWf5eurbluebCXWzOVyI+hh8gJlFeb8GuGFG7qenLyy2uarOfvrsHw7r4Y3t0HwyN8MDTCBx5a2/waG41GbMr9FRNHhEGtVttkm65ICgzS+J7rYTQakeYBDA33ZjvIyGg0wlsDBHu5sR26EIYeIgezWESczytvtJsqNaesyX52tVLAwG7eGB7hg+HdfTCiuy/CfXUcCEtEdJ0YeogcwGwRsfNsLtYfyMCe8wUoqzY1WSfMRyf14HT3xbAIHwzq5gU3tVKGaomIuiaGHiI7yiwy4F8HMvDvQ5nIKqkfmKpTKzE03LvRrqogJ90HTkTUVTD0ENlYjcmCH0/n4J/70/Hz+XzrbitfvRr3jgjHlGFhiAr1hErJuUGJiByJoYfIRi7klWP9gQz851AmCirqByHf1Mcff7yhO8YPCoZWxd1VRERyYegh6oDKGjP+dyIL6/ZnYP/lQuvyIE8t/t/IcEwb2R3d/fUyVkhERHUYeoiuw8mrJVh/IAPfHLmCsippULJCAO4cEIRpN3THHf0DufuKiMjJMPQQtVFZlRHfH7uK9Qcy8GtmiXV5uK8Of7whAn+IiUCINwcjExE5K9n/FF25ciUiIyPh5uaG0aNHY//+/S2uazQasXTpUvTu3Rtubm6Ijo7G5s2bHVgtuRpRFHEorQjP/vsYRr2aghe+OYFfM0ugVgq4Z2go/vHwaOx69g4k3NmXgYeIyMnJ2tOzfv16JCYmYtWqVRg9ejRWrFiBuLg4pKamIigoqMn6L774Iv7xj3/gk08+wYABA7BlyxZMnToVe/bswfDhw2V4BdSVpWaXYel/T2L3+QLrst6B7pg+qjumDg+Dv4dWxuqIiKi9ZA09y5cvx9y5czFnzhwAwKpVq7Bx40asXr0aCxYsaLL+F198gRdeeAETJ04EADz++OP48ccf8fbbb+Mf//hHs89RXV2N6upq6+3S0lIAUq+RSqWyXif51L3/ztIOxQYj3t12Hl/tz4BFBDQqBe4ZEoL7Y8IQ093HOiOys9RrK87WDq6K7eAc2A7OoWE72KItZAs9NTU1OHToEBYuXGhdplAoMHbsWOzdu7fZx1RXV8PNrfEuBJ1Oh59//rnF50lKSsKSJUuaLN+6dSv0eumomuTk5Ot5CWRjcreDWQT25AjYlKGAwSQFm2g/Cyb3MMHfLR25J9Pxv5OylugQcrcDSdgOzoHt4BySk5NhMBg6vB3ZQk9+fj7MZjOCg4MbLQ8ODsaZM2eafUxcXByWL1+OW2+9Fb1790ZKSgo2bNgAs9nc4vMsXLgQiYmJ1tulpaWIiIjA+PHjodPpkJycjHHjxvGEcjIyGo2yt8PeiwX468ZUnM0tBwD0D/bACxP7I7aXvyz1yMEZ2oHYDs6C7eAcGrZDZWVlh7fXqY7eevfddzF37lwMGDAAgiCgd+/emDNnDlavXt3iY7RaLbTapmMv1Gq19YPc8DrJR452SC8w4NVNp7DlZA4AwEevxl/G98f0GyJc9pBz/j44B7aDc2A7OAe1Wg2Tqek5C9tLttATEBAApVKJnJycRstzcnIQEhLS7GMCAwPx7bffoqqqCgUFBejWrRsWLFiAXr16OaJk6kIqqk34247z+OSnS6gxWaBUCHjwxh54amxf+Og1cpdHRER2INufshqNBjExMUhJSbEus1gsSElJQWxsbKuPdXNzQ1hYGEwmE/7zn/9g8uTJ9i6XugiLRcSGw5m4460dWLn9AmpMFtzcJwD/m38LXv79IAYeIqIuTNbdW4mJiYiPj8fIkSMxatQorFixAhUVFdajuWbNmoWwsDAkJSUBAPbt24crV65g2LBhuHLlCl5++WVYLBY899xzcr4M6iSOZhRjyQ8ncSS9GADQ3U+PF++JwriBwdYjsoiIqOuSNfRMmzYNeXl5WLRoEbKzszFs2DBs3rzZOrg5PT0dCkV9Z1RVVRVefPFFXLx4ER4eHpg4cSK++OIL+Pj4yPQKqDPILa3C65tT8Z/DmQAAvUaJhDv74OGbe/IEoERELkT2gcwJCQlISEho9r4dO3Y0un3bbbfh1KlTDqiKuoJqkxmrf76MD7adQ0WNdITffSPC8dyE/gj24uzJRESuRvbQQ2Rroijix9O5+OvGU0grkOZ1GBbhg5d/PwjDInzkLY6IiGTD0ENdSn55NRL/dQy7zuYBAII8tVhw9wBMGRYGhYLjdoiIXBlDD3UZp66WYu7nB3GluBIapQKP3NITT9zRBx5afsyJiIihh7qIzSeykfivozDUmNEzwB2fzIpBnyBPucsiIiInwtBDnZooili5/Tze2noWAHBznwCsnDEC3nrOoEpERI0x9FCnVWU049mvf8UPx64CAGaPicSL90S57OkjiIiodQw91Clll1Th0S8O4tfMEqgUApZOHowZo7vLXRYRETkxhh7qdI5mFOPRzw8it6wavno1PnwgBje60NnQiYjo+jD0UKfy3dErePbrX1FjsqBfsAc+nXUDuvvr5S6LiIg6AYYe6hQsFhFvJ6di5fYLAIC7BgRhxR+HwdONA5aJiKhtGHrI6ZVXm/D0+qNIPpUDAHjstt54Nq4/lJxskIiI2oGhh5xaRqEBcz8/iDPZZdCoFHj9viGYOjxc7rKIiKgTYughp7X/UiEe+8chFFbUIMBDi49nxWBEd1+5yyIiok6KoYec0voD6Xjx2xMwmkUMDvPCxw+ORDcfndxlERFRJ8bQQ07FZLZg2aYzWL37EgDgniGheOv/RUOnUcpcGRERdXYMPeQ0SiuNePrrI9YzpD89th+evKsPBIEDlomIqOMYesgp5FYC/+/jfbiYb4BOrcTy+6Nx95BQucsiIqIuhKGHZLfvUiGWH1ei0mxAN283fDxrJAaHectdFhERdTEMPSSrYkMN/rzuGCrNAoZHeOOjWSMR5Okmd1lERNQFMfSQrN7amooigxEhOhFfzBkJDz0DDxER2YdC7gLIdR3PLMGX+9IBAH/oaYFWzSO0iIjIfhh6SBYWi4gXvzsBUQQmDQ1BX29R7pKIiKiLY+ghWfzrYAaOZRTDQ6vC83H95C6HiIhcAEMPOVyxoQavbz4DAHhqbF8Ee3EcDxER2R9DDzncm1ukwcv9gz0RPyZS7nKIiMhFMPSQQ/2aWYyv9kuDl5dOHgS1kh9BIiJyDH7jkMNYLCJe+lYavDx1eBhG9/KXuyQiInIhDD3kMOsPZuBYZgk8tSosnDhA7nKIiMjFMPSQQxRV1A9efnpcP866TEREDsfQQw7xxpZUFBuMGBDiiVmxPeQuh4iIXBBDD9nd0YxirDtQN3h5MFQcvExERDLgtw/ZldkiYlHtzMv3jgjDqJ5+cpdEREQuiqGH7GrdgXT8Wjd4+e4oucshIiIXxtBDdlNYUYM3NqcCAP4yvh8CPbUyV0RERK6MoYfs5o3NZ1BSaURUqBceuJGDl4mISF4MPWQXh9OLsO5ABgDglcmDOHiZiIhkx28isrm6wcsA8IeYcIyM5OBlIiKSH0MP2dxX+9Nx4kopPN1UWHA3Z14mIiLnwNBDNlVQXo03a2defjauPwI8OHiZiIicA0MP2dTrm8+gtMqEQd28MHM0By8TEZHzYOghmzmUVoR/HcwEIM28rFQIMldERERUT/bQs3LlSkRGRsLNzQ2jR4/G/v37W11/xYoV6N+/P3Q6HSIiIvD000+jqqrKQdVSS8wWES99Kw1evn9kOGJ6+MpcERERUWOyhp7169cjMTERixcvxuHDhxEdHY24uDjk5uY2u/5XX32FBQsWYPHixTh9+jQ+++wzrF+/Hv/3f//n4MrpWl/uS8OprFJ4uanw/AQOXiYiIuejkvPJly9fjrlz52LOnDkAgFWrVmHjxo1YvXo1FixY0GT9PXv24KabbsKMGTMAAJGRkZg+fTr27dvX4nNUV1ejurraeru0tBQAYDQaoVKprNfp+hWUV+PNLdLMy4nj+sJLq2jXe1q3LttBXmwH58B2cA5sB+fQsB1s0RaCKIpih7dyHWpqaqDX6/H1119jypQp1uXx8fEoLi7Gd9991+QxX331FZ544gls3boVo0aNwsWLF3HPPffgwQcfbLG35+WXX8aSJUua3ZZer7fZ63FlX55XYH+eAuHuIv4yxAwO5SEiIlszGAyYMWMGSkpK4OXldV3bkK2nJz8/H2azGcHBwY2WBwcH48yZM80+ZsaMGcjPz8fNN98MURRhMpnw2GOPtbp7a+HChUhMTLTeLi0tRUREBMaPHw+dTofk5GSMGzcOarXaNi/MxRxKK8L+vQcAAO/MHI1hET7t3obRaGQ7OAG2g3NgOzgHtoNzaNgOlZWVHd6erLu32mvHjh1YtmwZ/va3v2H06NE4f/485s+fj1deeQUvvfRSs4/RarXQapvOFaNWq60f5IbXqe1MZguWbJR2a/3xhgjc0CuwQ9tjOzgHtoNzYDs4B7aDc1Cr1TCZTB3ejmyhJyAgAEqlEjk5OY2W5+TkICQkpNnHvPTSS3jwwQfxyCOPAACGDBmCiooKPProo3jhhRegUMh+MJpL+ccvaTidVQpvnRrPcfAyERE5OdlSgkajQUxMDFJSUqzLLBYLUlJSEBsb2+xjDAZDk2CjVCoBADINTXJZeWXVeHvrWQDAcxP6w89dI3NFRERErZN191ZiYiLi4+MxcuRIjBo1CitWrEBFRYX1aK5Zs2YhLCwMSUlJAIBJkyZh+fLlGD58uHX31ksvvYRJkyZZww85RtL/TqOs2oSh4d744w3dO7ax8lwElRwDKscA6o7tIiMiImqJrKFn2rRpyMvLw6JFi5CdnY1hw4Zh8+bN1sHN6enpjXp2XnzxRQiCgBdffBFXrlxBYGAgJk2ahFdffVWul+CSDl4uxIbDVyAIwCsdnXnZbITqq3sRm3cG4jvvAGExQJ+xQO+7gLARgIJhlmzMYgEubgcq8oHImwDvcLkrIiIHkX0gc0JCAhISEpq9b8eOHY1uq1QqLF68GIsXL3ZAZdQci0XEkh9OAQCmjYxA9HUcrdXIobUQ8s7AAgUUogXIPCBddiQBbj5Ar9ulENTnLsCrW0fLJ1dmrAKO/wvY8wGQn1q/3L8P0OsO6bMWeTOg85GrQiKyM9lDD3Uu3xy5guNXSuChVeEv4/t3bGOVxVK4AXA8/AEMnPoXqC/vBC6kABd3AFXFwKlvpQsABEZJ4afPXUD3MYDarWPPT67BUAgc/AzY9zFQUTvbu9ZLCjtZR4GC89LlwCeAoJB6G3vdLl3CRwEqFx6vJopSj1jhRaDokvSz9Cqg8wU8QwHPYOmnRzDgGQJo3OWuuPMRRcBUBdQYAKMBMFY287Ph9Qrpp8Us9VT2vA1Q8uiytmLooTYz1JjwxhZpDqV5d/RBoGfTqQDa5ae3AUMBxIB+SAu4AwO9woCYeOliNgFXDkkB6HyKdD3vtHTZ+wGg0kl/lfe5S9oVFtAXEOwwK6IoAmaja3/xdVaFl4Bf/gYc+Yf0hQEAXuHAjY8DI2YBbl5S8L78sxSyL+4ACs7V9zbuehNQ64EeN9WHoOBB9vmcycliAcqy6kON9XJJutSUtX1bWi8p/HgENxOKQqX72hKOLBagphyoLgWqShv/bG5Z3c+acsCzGxAyWGqr4CGAX095dpObaoD8s0DOSSDnBJB7CqjIaybEGK7/OX5eDuj9gajfA4PvA3qM4ZCA38DQQ2320c6LyCmtRoSfDnNuiuzYxgovAftWAQDMdy2BePaa6cWVKqD7aOlyx/9Jf61f3A6c3yYFobIs4HyydAEA74j6ANTrNsDNW/qPs9F/kmUNrpdc8x9mWTP/iZZIy0UL4B4I+PYEfCOl/0R9e9b+jJT+Q+9qX4SdWeZBYM97wOkfpLYDgJAhwJgngUFTG/9VrPMBon4nXQCgJLM+AF3cIX1JNfycuQdJn6+6ENRZxgOZTUBpZtNAU9eDY2rtpM2C9Dp9IwG/XoBXmNQLW5YtXcprfxoN9b9v+Wdbr0fjWR+A1Drp9+zaAIPrPCI36xhw9n/1t9V6ICiqPgQFD5IuttqNKYrS/0d14SbnJJBzStqFamnnvDJKjfR+qN1rf+prfza8rgc0eun9Tv0fYCgADq2RLh7B0md80L1A+A0Ap3FpgqGH2iSrpBIf7boAAFh4dxTc1B38a+LHlwFzDdDrDoi9xzb+T6o5ej/pL5nB90n/yeSeBs7/KAWgtD1ASQZwaK10EZTSfwzt+Qv1t1TkSZfM/U3vU+ulLwTfyAZhqDYQ+XRvXy+RxSwFPEO+tFuh7mfD64aC+tuVRYDW85q/ppv569oj2H67A0VR+pKqLGp60QcAodHSe2HPYGixAGc3A3veB9L31C/vMxYY82dpF0Bbnt87HBj+gHQRRekLrC4Ape2Wdo8d/7d0AQD/vvUByK+n1NPh5g1oPBzzhWMxS5/L8hygLEcKINbrtZeybKD0SutfwIIS8O0hhRrfntJPv17Sa/Lp8dufHVGUgkvDEHRtKKq7GCuk382CMqlnrTUKVe176lX/3lpve15zn5cUForTgOzjUtvlnpbCwZVD0qUh74jaAFTbKxQyRHrNrfWU1Bik3uackw0uJ6TPenO0XvUhK3iQFBjV+vrg0jDMqHTSH3vtYTYBl3cBJ/4jhfzyHOmPyX2rpNc3aIr0f2boMP5hVouhh9rkzc2pqDJaMCrSD3cPbn7yyDZL/0UapyMogLhX2//LKAhA8EDpctOT0n9EabulEHQ+RfqPtGHgUWql/yAb/ufY8D/Q1u5z8wIUailUFV2u3QVwSfpZdFnqGTAapK7r3FPN1KqQdqn4RdaHIo178yGmIq/2P892/oVbFzCae/6GdL6AR0j9X9ieIY3Dkc4falOZ9NqMZbXbLa7fvqGw+WBTWQSI5taf281HCj+h0UC3YdJ/wr49Ox4MjJXAsXXSLs+C89IyhRoYej8QO0/6orlegiDtJgkZDIxJAEzV0m6vuhB05ZD0WSs4J40HavRYRf3nx81bev3Wz5R3g8s1t7VegModKnOl1AtTVVgbZHJrA0Ru42BjyK/vzfotSq0UYqzBpmd9sPGO6Ni4EEGofS1eQGC/1tetC0d1F1Nlg9897/rfQa2nFAY68mVtMUvvY84JIPtEfUgpyai/nN1cv75KZ+0VUgRGoVvRVSh+OlkfdAovotnfT0EhBWBrwKkNUt7h9g0bShXQ+07pcs87wIVtwMkNwJlN0mvb87508e0JDL5XCkBBA106AMl2wlG5lJaWwtvbGyUlJdDpdNi0aRMmTpzIacZbcSyjGJNX7gYAfJ9wE4aG+1z/xiwW4LOx0hfGiHjg9+/BaDTath1Krkjd9XX/kao6OPaoNaaa2kBUF4YuS5e6YHS9++t1vlIviXsg4O5fez2g/mfddZ2v1MtSltX6X9fmalu+6uapdFI9dRc3b6mHIfeU1Kt3La0XEDK0NgRFS0HIv3fbxiRUFAAHPgX2fyx98QPSF+YNDwGj/gR4hdrylTWv4XigtN21obUYsDj4rNyCQtrt5hFU26sXJIVbj2Cp188jBPAOk8a6cHeHpLJY+lxmn6jdJXWivlfot+gDascM1QaboIFA4ADnOrDCWAmcS5YCUOpmKVjWCehf22t+rzQW0sk1/H6orKy0fn93uhOOUucgiiJe+a/Ug3DviLCOBR5A+iW8ckjq/r/jhY4X2BzvMPtstzkqjfRF7d+76X2iKP1lfm0PkanqmhDjL4WbumU6v3Z2c4dJf522RBSl3pjynNpwVPvTelsKRmJZNgRzNUS1OwS9nzTmoWGI+a2LWtf885tqpL+Urx6VxltkHZW+bKpLgbSfpUsdtTsQOrQ+BIVGAwH96t+PggvA3pXA0a/q/yP3jgBufAIY8aDUO+Ao144HAuqPxKmqHTNWVSJdqkvqrze5r7TxfbVfvKJaD6HuqChrkAmq311Zd5/en4NX20vnIw367TGmfpnFLP2u1u4as2T9ipIrZ+Hd+wYoQofU9+B4BMlVddupdcDA30uX6nKpN+vEBmlsWn4qsGOZdAkZIo3/GXyv1BPdXqIovW+iuf6naJGuCwqnnP6BoYdatfF4Fg6mFUGnVuK5uA6eX8tYKY3lAYCbn5b+Cu3KBKF2fE2wNCBbzjr0ftKllXBkqqnB/zb9gLvv+b1tez5VmvpdW3XMRiAvtT4EXT0qfdkYK4D0vdLF+nid9Je1m7e0+7Ju90JotDQ4eeCU9o+FsBdBqB946nl9u4GNVQZs2fRfxE2ayh5oR1Io6/+AGTQFZqMRu2p7GBSduR20HsCQP0iXqhJp19eJ/0gHhmQfly4pS6TxhxDqQ0vDIGOxNA40dfe1tis+YjTw8FZHvco2c5L/KcgZVRnNeO1/0iHqf7qtF0K8O9h9+8vfpF1BXuHSeAtyLoIAUXDQfwlKdf14meEzpWUWs3TUT9ax+l6h7F+lw5AzD9Q/tm+cNDg58uauOTZBqYZZacddsuS63LyBYdOli6EQOP291AN0+SegON22z9XWsWYOxtBDLVq9+xIyiyoR4uWGR2/t1bGNlecCPy2Xro99ueVdIeS6FEqpJyooCoj+o7TMYgEKL0ghqDQT6Deh9V15RNQ2ej8gZrZ0Kc+VBmkLSmncl6CUfh+Fa64rlO27zwkx9FCz8sqq8bft0iHqz9/dH3pNBz8q21+V/mIPi5EG0RG1hUIhDbbsBAMuiTotj6DOMVbJBjiUn5q1PDkV5dUmRId7Y3J0BwcG55wEDn8uXY9bxiNIiIhIFvz2oSZOXS3F+gMZAICXfjcQio6cRV0UgS0vSPt3B04But9omyKJiIjaiaGHGhFFEX/deAoWEbhnaChGRvp1bIPnf5SOElBqpLE8REREMmHooUZ+PJ2LPRcKoFEpsGBCBw9RN5ukXh4AGP0naeZXIiIimTD0kFWNyYJlm04DAB6+uSci/PQd2+DhtdJEWDo/4JZnOl4gERFRBzD0kNUXv6ThUn4FAjw0eOL2ZmYYbo+qEmD7Mun6Hf/nlDNzEhGRa2HoIQBAUUUN3v3xLADgL+P7w9OtgzOQ/vS2dCLNgH7SPBBEREQyY+ghAMC7KedQWmXCgBBP3D8yomMbK7oM/PKhdH38Xzt29mYiIiIbYeghnM8twxe/pAEAFv1uIJQdOUQdkM6vZa4Bet0O9B3f4fqIiIhsgaGH8OrG0zBbRIyNCsaYPgEd21j6PuDkNwAEYPyrXfPcSERE1Ckx9Li4XWfzsD01DyqFgP+b2MFD1C0WYMtC6fqIB6WTSRIRETkJhh4XZjJb8NeNpwAAs2Ij0SvQo2MbPLkBuHIIULsDd7xogwqJiIhsh6HHha07kIGzOeXw0asx/64OntDRWCmN5QGAW54GPIM7XB8REZEtMfS4qNIqI95Jlg5Rf+quvvDWd/AIq1/+BpRkAF7hQGyCDSokIiKyLYYeF7Vy23kUVNSgd6A7Zt7Yo2MbK88FflouXR+7GFDrOl4gERGRjTH0uKC0ggqs2X0ZAPDCPVFQKzv4Mdj+KlBTDnQbAQz+Q8cLJCIisgOGHheUtOkMaswW3NI3AHf0D+rYxnJOAoc/l67HLQMU/EgREZFz4jeUi/nlYgE2n8yGQgBevGcghI7MoyOK0lnURQsQ9XugR6ztCiUiIrIxhh4XYrGI1kPUp4/qjv4hnh3b4PkfgYvbAYUaGLfEBhUSERHZD0OPC/nP4UycuFIKT60KieP6dWxjZpPUywMAo/8E+PXqeIFERER2xNDjIiqqTXhzSyoAIOHOPvD30HZsg4fXAvmpgM4PuPXZjhdIRERkZww9LuKjnReQW1aN7n56zL4psmMbqyoBti+Trt++END5dLQ8IiIiu2PocQGVNWZ88tMlAMDCuwdAq1Je/8aqSoEv7wcMBYB/X2DkHBtVSUREZF8quQsg+9t3qQCVRjPCfHSYMDjk+jdkKAT+cR9w9TDg5g3c+zGg7OBMzkRERA7C0OMCdp7NAwDc2i/g+g9RL88DvpgC5JyQxvHM+hYIjbZZjURERPbG0OMCdtWGntv6BV7fBkqzgM8nSwOX3YOA+O+BoCgbVkhERGR/DD1dXGaRARfyKqBUCBjTJ6D9GyhOB/7+e6DoEuAVBsz6HgjoY/tCiYiI7Iyhp4vbdTYfADCiuw+83No5/qbwohR4SjIAnx5SD49vpO2LJCIicgCGni5u59lcAMCtfdu5aysvVQo85dmAfx+ph8c7zA4VEhEROQZDTxdmNFuw53wBAOC2/u0IPdnHgc+nAIZ8IGggMOs7wKODJyYlIiKSmVPM07Ny5UpERkbCzc0No0ePxv79+1tc9/bbb4cgCE0u99xzjwMr7hyOZhSjrNoEP3cNBnfzbtuDrhwG1v5OCjyh0UD8fxl4iIioS5A99Kxfvx6JiYlYvHgxDh8+jOjoaMTFxSE3N7fZ9Tds2ICsrCzr5cSJE1Aqlfh//+//Obhy57czVTpq6+Y+AVAo2nCoevov0lFaVcVA+A3SLi13f/sWSURE5CCy795avnw55s6dizlzpJl9V61ahY0bN2L16tVYsGBBk/X9/Pwa3V63bh30en2Loae6uhrV1dXW26WlpQAAo9EIlUplvd4V1Y3nubm332++RuHyLij/9QAEowGW7rEw3/8VoHIHHPDe1NXWVduhs2A7OAe2g3NgOziHhu1gi7YQRFEUO7yV61RTUwO9Xo+vv/4aU6ZMsS6Pj49HcXExvvvuu9/cxpAhQxAbG4uPP/642ftffvllLFmypMnyr776Cnq9/rprd3blRuDFg0qIEPBKjAlempbXDSo5hlGX3oNSNCLXczD295oPs6KDJyQlIiKyIYPBgBkzZqCkpAReXl7XtQ1Ze3ry8/NhNpsRHBzcaHlwcDDOnDnzm4/fv38/Tpw4gc8++6zFdRYuXIjExETr7dLSUkRERGD8+PHQ6XRITk7GuHHjoFZ3rdMpfH8sC+LB44gK8cQfp8S2uJ5wZiOU37wHQTTC0jcOvvd+hjiVmwMrlRJ8V22HzoTt4BzYDs6B7eAcGrZDZWVlh7cn++6tjvjss88wZMgQjBo1qsV1tFottNqmvRZqtdr6QW54vavYfaEQAHBb/6CWX9vxr4ENjwKiGRg4BYp7P4FC1UqXkJ11xXbojNgOzoHt4BzYDs5BrVbDZDJ1eDuyDmQOCAiAUqlETk5Oo+U5OTkICWn9xJgVFRVYt24dHn74YXuW2ClZLCJ2nZMmJWzx1BNH/gH85xEp8Az9I3DfZ4CMgYeIiMjeZA09Go0GMTExSElJsS6zWCxISUlBbGzLu2QA4N///jeqq6vxwAMP2LvMTudUVinyy6vhrlEipodv0xX2fwJ8Nw+ACMTMBqZ8CCg7dacfERHRb5L9my4xMRHx8fEYOXIkRo0ahRUrVqCiosJ6NNesWbMQFhaGpKSkRo/77LPPMGXKFPj785Dqa+06Jx2qHts7ABrVNbl2zwfA1hek66MfAya8BlzvmdeJiIg6EdlDz7Rp05CXl4dFixYhOzsbw4YNw+bNm62Dm9PT06FQNP7iTk1Nxc8//4ytW7fKUbLTq5uf57Z+15xgdOebwPa/Stdvfhq4azEDDxERuQzZQw8AJCQkICEhodn7duzY0WRZ//79IeOR9k6tvNqEQ2lFAIBbG47n2fEasKO2t+yOF4Bbn2XgISIil+IUoYdsZ++FApgsIiL99ejh7y4tLL0qhR4AGPcKcNOT8hVIREQkE9lPQ0G2ZT2resNenpPfAhCBiBsZeIiIyGUx9HQhoihi59m68TwNQ88G6efge2WoioiIyDkw9HQhlwsMyCishFop4MZetUe1FacDmQcACMDAybLWR0REJCeGni5kV20vzw2RfnDX1g7XOvmN9DPyZsCz9QkfiYiIujKGni6kbtdWo/E8J2p3bQ2aKkNFREREzoOhp4uoNpmx90IBgAbjeQouAFlHAUHJXVtEROTyGHq6iIOXi1BpNCPIU4sBIZ7SwrpdWz1vBdwDWn4wERGRC2Do6SLqxvPc0jcQQt2kg3Whh0dtERERMfR0FdZD1fvX7trKOwvknAAUKmDA72SsjIiIyDkw9HQBOaVVOJNdBkEAbulTuxurbm6e3ncCej/5iiMiInISDD1dQN2uraHhPvB11wCi2OCoLe7aIiIiAhh6ugTrrq2+tb08uaeA/FRAqQEGTJSxMiIiIufB0NPJmS0ifj6fD6DBeJ66Xp4+4wA3b5kqIyIici7XFXpMJhN+/PFHfPTRRygrKwMAXL16FeXl5TYtjn7br5nFKDYY4emmQnS4j7Rri+faIiIiakLV3gekpaVhwoQJSE9PR3V1NcaNGwdPT0+8/vrrqK6uxqpVq+xRJ7Vg11mpl+fmPgFQKRXA1aNA4UVApQP6TZC3OCIiIifS7p6e+fPnY+TIkSgqKoJOp7Munzp1KlJSUmxaHP22nWdzATSYhbmul6ffeEDrIVNVREREzqfdPT0//fQT9uzZA41G02h5ZGQkrly5YrPC6LeVGIw4mlEMoPZ8W6JYPyEhj9oiIiJqpN09PRaLBWazucnyzMxMeHp62qQoapufz+fDIgJ9gzzQzUcHXDkEFKcDaneg73i5yyMiInIq7Q4948ePx4oVK6y3BUFAeXk5Fi9ejIkTeXi0I+269qzqdUdt9b8b0OhlqoqIiMg5tXv31ltvvYUJEyZg4MCBqKqqwowZM3Du3DkEBATgn//8pz1qpGaIolg/P0+/QMBi4bm2iIiIWtHu0BMREYFjx45h/fr1OHbsGMrLy/Hwww9j5syZjQY2k32dyy1HdmkVtCoFRvX0AzL2AWVXAa0X0Ges3OURERE5nXaFHqPRiAEDBuC///0vZs6ciZkzZ9qrLvoNdbu2buzlDze1sv6orQH3ACqtjJURERE5p3aN6VGr1aiqqrJXLdQOOxuO57GYgVPfSXfwqC0iIqJmtXsg87x58/D666/DZDLZox5qg8oaM/ZdKgQA3NYvAEjbDZTnAG4+QK/bZa2NiIjIWbV7TM+BAweQkpKCrVu3YsiQIXB3d290/4YNG2xWHDXvl0sFqDFZEOajQ+9AD2Bf7XseNQlQaVp/MBERkYtqd+jx8fHBfffdZ49aqI3qD1UPgGAxA6e/l+7gUVtEREQtanfoWbNmjT3qoHZodKj6pZ2AoQDQBwCRt8pcGRERkfNqd+ipk5eXh9TUVABA//79ERgYaLOiqGUZhQZczKuAUiFgTJ8AYEvtrq2BvweU192cREREXV67BzJXVFTgoYceQmhoKG699Vbceuut6NatGx5++GEYDAZ71EgN7Don9fKM6O4DL5UInP5BuoNHbREREbWq3aEnMTERO3fuxA8//IDi4mIUFxfju+++w86dO/GXv/zFHjVSA9bxPH0DgYvbgaoSwCMY6DFG5sqIiIicW7v3h/znP//B119/jdtvv926bOLEidDpdLj//vvx4Ycf2rI+asBotmD3+QIAwG39A4H9b0l3DJwCKJTyFUZERNQJtLunx2AwIDg4uMnyoKAg7t6ysyPpxSivNsHPXYPBQVrgzEbpDh61RURE9JvaHXpiY2OxePHiRjMzV1ZWYsmSJYiNjbVpcdRY3a6tm/sEQHHhR6CmDPAKA8JHyVwZERGR82v37q13330XcXFxCA8PR3R0NADg2LFjcHNzw5YtW2xeINVrdKj6ifekhYOmAop2Z1ciIiKX0+7QM3jwYJw7dw5ffvklzpw5AwCYPn06z7JuZ/nl1Th+pQQAcEtPHbB5s3QHj9oiIiJqk+ua2EWv12Pu3Lm2roVa8fO5fADAwFAvBF3dCRgNgE8PIGyEzJURERF1Du3eL5KUlITVq1c3Wb569Wq8/vrrNimKmtrV8KzqJ2snJBw0FRAEGasiIiLqPNodej766CMMGDCgyfJBgwZh1apVNimKGrNYROukhHf01AHnkqU7eNQWERFRm7U79GRnZyM0NLTJ8sDAQGRlZdmkKGrsVFYp8str4K5RIqZyL2CqAvx6AyFD5S6NiIio02h36ImIiMDu3bubLN+9eze6detmk6KosbqjtmJ7B0B1+ltp4eB7uWuLiIioHdodeubOnYunnnoKa9asQVpaGtLS0rB69Wo8/fTT1zW4eeXKlYiMjISbmxtGjx6N/fv3t7p+cXEx5s2bh9DQUGi1WvTr1w+bNm1q9/N2JnXjecb21ADnf5QW8qgtIiKidmn30VvPPvssCgoK8MQTT6CmpgYA4Obmhueffx4LFy5s17bWr1+PxMRErFq1CqNHj8aKFSsQFxeH1NRUBAUFNVm/pqYG48aNQ1BQEL7++muEhYUhLS0NPj4+7X0ZnUZ5tQmH0ooAAGMVBwGLEQgcAAQPlLkyIiKizqXdoUcQBLz++ut46aWXcPr0aeh0OvTt2xdarbbdT758+XLMnTsXc+bMAQCsWrUKGzduxOrVq7FgwYIm669evRqFhYXYs2cP1Go1ACAyMrLV56iurkZ1dbX1dmlpKQDAaDRCpVJZrzurn1JzYbKI6OGnh9/F/wIAzFGTYXHimtur7v135nZwBWwH58B2cA5sB+fQsB1s0RaCKIpiRzaQlpaGiooKDBgwAIp2zAxcU1MDvV6Pr7/+GlOmTLEuj4+Pt565/VoTJ06En58f9Ho9vvvuOwQGBmLGjBl4/vnnoVQ2f8LNl19+GUuWLGmy/KuvvoJer29zvXL510UFducocHdgCVaWJUABM1KiXke5W9PB5ERERF2VwWDAjBkzUFJSAi8vr+vaRpt7elavXo3i4mIkJiZalz366KP47LPPAAD9+/fHli1bEBER0abt5efnw2w2Nzl5aXBwsHWm52tdvHgR27Ztw8yZM7Fp0yacP38eTzzxBIxGIxYvXtzsYxYuXNio5tLSUkRERGD8+PHQ6XRITk7GuHHjrD1HzkQURbz5zs8AKpHQNxeKw2aIQYNx670Py12aTRmNRqduB1fBdnAObAfnwHZwDg3bobKyssPba3Po+fjjj/GnP/3Jenvz5s1Ys2YNPv/8c0RFRSEhIQFLlizBp59+2uGiWmKxWBAUFISPP/4YSqUSMTExuHLlCt58880WQ49Wq21215tarbZ+kBtedyaX8iuQWVQJtVLAgMIUAIAw5F6nrNUWnLUdXA3bwTmwHZwD28E5qNVqmEymDm+nzaHn3LlzGDlypPX2d999h8mTJ2PmzJkAgGXLllnH5rRFQEAAlEolcnJyGi3PyclBSEhIs48JDQ2FWq1utCsrKioK2dnZqKmpgUajafPzdwY7U3MBAHdFCFCm/Swt5FFbRERE16XNg3AqKysb7UPbs2cPbr31VuvtXr16ITs7u81PrNFoEBMTg5SUFOsyi8WClJQUxMbGNvuYm266CefPn4fFYrEuO3v2LEJDQ7tc4AGAXbXn25rpdRQQLUC34YBfT3mLIiIi6qTaHHp69OiBQ4cOAZDG45w8eRI33XST9f7s7Gx4e3u368kTExPxySef4O9//ztOnz6Nxx9/HBUVFdYeo1mzZjU6DP7xxx9HYWEh5s+fj7Nnz2Ljxo1YtmwZ5s2b167n7QyqTWbsvVAAABhRtl1ayF4eIiKi69bm3Vvx8fGYN28eTp48iW3btmHAgAGIiYmx3r9nzx4MHjy4XU8+bdo05OXlYdGiRcjOzsawYcOwefNm6+Dm9PT0RkeERUREYMuWLXj66acxdOhQhIWFYf78+Xj++efb9bydwcHLRag0mjHQowL6rNoJGwdNlbcoIiKiTqzNoee5556DwWDAhg0bEBISgn//+9+N7t+9ezemT5/e7gISEhKQkJDQ7H07duxosiw2Nha//PJLu5+ns6k7weij/r9CyBGB8FGAT9uOjCMiIqKm2hx6FAoFli5diqVLlzZ7/7UhiDrmfE45AOCm6l3SAp5RnYiIqEPafe4tcoyMIgO6IR+BxccACMDAKXKXRERE1Kkx9DghURSRWVSJe5S1u/F6jAG8OAMzERFRRzD0OKEigxGGGjN+Vxd6OICZiIiowxh6nFBGoQHdhRxEKy4CggIYOFnukoiIiDo9hh4nlFlUiXsU+6QbkbcAHkHyFkRERNQF2Cz0ZGRk4KGHHrLV5lxaRpEB0YoL0o1+cfIWQ0RE1EXYLPQUFhbi73//u60259IyiwyIEKTzbsGvt7zFEBERdRFtnqfn+++/b/X+ixcvdrgYkmQWVSJCkCYnhG8PeYshIiLqItoceqZMmQJBECCKYovrCIJgk6JcXVFBLrwEg3TDp7u8xRAREXURbd69FRoaig0bNsBisTR7OXz4sD3rdBmiKEJRnA4AMOsCAI27zBURERF1DW0OPTExMdazrDfnt3qBqG3yyqsRbMkBAAh+kfIWQ0RE1IW0effWs88+i4qKihbv79OnD7Zv326TolyZNJ5HGsSs4HgeIiIim2lz6Lnllltavd/d3R233XZbhwtydY0GMfsw9BAREdlKm3dvXbx4kbuvHCCjsMHh6uzpISIispk2h56+ffsiLy/PenvatGnIycmxS1GujD09RERE9tHm0HNtL8+mTZtaHeND1yezsALhnKOHiIjI5njuLSdjKLwKN8EIUVAA3hFyl0NERNRltDn0CILQZPJBTkZoWxaLCFVp7Rw9HqGAUi1zRURERF1Hm4/eEkURs2fPhlarBQBUVVXhscceg7t748nzNmzYYNsKXUhuWTVCaufoUXKOHiIiIptqc+iJj49vdPuBBx6weTGuTjrRqDSeR/CNlLcYIiKiLqbNoWfNmjX2rIMAZBQZ0L3ucHUeuUVERGRTHMjsRDILeXZ1IiIie2HocSKZRZWIULCnh4iIyB4YepzI1cJShKJAusExPURERDbF0ONEagozoBREWBQawCNY7nKIiIi6FIYeJ2G2iNCUZUjXvbsDCjYNERGRLfGb1Ulkl1ahG6TxPCrO0UNERGRzDD1OIrPB2dUFHrlFRERkcww9TiKjiIerExER2RNDj5OQZmPm4epERET2wtDjJDI4MSEREZFdMfQ4idzCQgQKJdIN9vQQERHZHEOPk7AUpgMAzGpPQOcrczVERERdD0OPEzCaLXCrkObosfh0BwRB5oqIiIi6HoYeJ5BdUoUwztFDRERkVww9TiCj0GAdxCzwnFtERER2wdDjBDI5Rw8REZHdMfQ4Ac7RQ0REZH8MPU4go8EpKNjTQ0REZB8MPU6guDAXXkKldMOnu7zFEBERdVFOEXpWrlyJyMhIuLm5YfTo0di/f3+L665duxaCIDS6uLm5ObBa27MUpgEAjLoAQOMuczVERERdk+yhZ/369UhMTMTixYtx+PBhREdHIy4uDrm5uS0+xsvLC1lZWdZLWlqaAyu2rWqTGe6VmdINjuchIiKyG5XcBSxfvhxz587FnDlzAACrVq3Cxo0bsXr1aixYsKDZxwiCgJCQkDZtv7q6GtXV1dbbpaWlAACj0QiVSmW9LpeMAgPCa+foUfj2kLUWudS9Zld87c6E7eAc2A7Oge3gHBq2gy3aQtbQU1NTg0OHDmHhwoXWZQqFAmPHjsXevXtbfFx5eTl69OgBi8WCESNGYNmyZRg0aFCz6yYlJWHJkiVNlm/duhV6vR4AkJyc3MFXcv3OFAvWw9UvFBhxetMm2WqRm5ztQPXYDs6B7eAc2A7OITk5GQaDocPbkTX05Ofnw2w2Izg4uNHy4OBgnDlzptnH9O/fH6tXr8bQoUNRUlKCt956C2PGjMHJkycRHh7eZP2FCxciMTHReru0tBQREREYP348dDodkpOTMW7cOKjVatu+uDYqO5iJ8PNS6OkVcyd6Dp8oSx1yMhqNsrcDsR2cBdvBObAdnEPDdqisrOzw9mTfvdVesbGxiI2Ntd4eM2YMoqKi8NFHH+GVV15psr5Wq4VWq22yXK1WWz/IDa872tWSasTWHq6uCugFuPAvl5ztQPXYDs6B7eAc2A7OQa1Ww2QydXg7sg5kDggIgFKpRE5OTqPlOTk5bR6zo1arMXz4cJw/f94eJdrdlcIKhAv50g0OZCYiIrIbWUOPRqNBTEwMUlJSrMssFgtSUlIa9ea0xmw24/jx4wgNDbVXmXZVXnAFWsEIEQrAu+nuOSIiIrIN2XdvJSYmIj4+HiNHjsSoUaOwYsUKVFRUWI/mmjVrFsLCwpCUlAQAWLp0KW688Ub06dMHxcXFePPNN5GWloZHHnlEzpdx/YrTAQBGj27QKNmFSkREZC+yh55p06YhLy8PixYtQnZ2NoYNG4bNmzdbBzenp6dDoajvkCoqKsLcuXORnZ0NX19fxMTEYM+ePRg4cKBcL+G6VRnN8Ky8AmgAgaefICIisivZQw8AJCQkICEhodn7duzY0ej2O++8g3feeccBVdmfdHb12kHM/pHyFkNERNTFyT4jsyuTzq4uHa4u+EbKWwwREVEXx9AjI6mnRwo9PHKLiIjIvhh6ZJRRZECEovYcYxzTQ0REZFcMPTK6WliGUBRIN9jTQ0REZFcMPTKqyU+DUhBhVmgAj+DffgARERFdN4YeGSlKpDl6TJ4RgIJNQUREZE/8ppWJocYE7+qrAACFf0+ZqyEiIur6GHpk0nCOHjXn6CEiIrI7hh6ZNJyjh4OYiYiI7I+hRyYZhQ3m6OHh6kRERHbH0COTzCIDwmt3b7Gnh4iIyP4YemSSW1CIQKFUusGeHiIiIrtj6JGJseCy9FPtCeh85S2GiIjIBTD0yERZmgEAMHt1l7kSIiIi18DQI4OyKiP8arIAACoerk5EROQQDD0yaDhHj4oTExIRETkEQ48MpNDDOXqIiIgciaFHBhmFBs7RQ0RE5GAMPTLILOQcPURERI7G0CODgoIceAmV0g0fHr1FRETkCAw9MrAUpgEAqt0CAI1e5mqIiIhcA0OPDDRlUuixeLOXh4iIyFEYehysxGBEgDEbAKAO6CVzNURERK6DocfBMooM9XP0+EXKWwwREZELYehxsMwiHq5OREQkB4YeB8ssqkQ4JyYkIiJyOIYeB7tSWFEfetjTQ0RE5DAMPQ5WmpcJrWCCRVACXuFyl0NEROQyGHocTCy6DACo1ocCSpW8xRAREbkQhh4HEkUR6rIM6QZnYiYiInIohh4HKjIYEWzOAQCoA3rKXA0REZFrYehxoMxGc/Qw9BARETkSQ48DZRRWIkLBI7eIiIjkwNDjQJlFBs7RQ0REJBOGHge6UliKUBRIN9jTQ0RE5FAMPQ5UmZcGpSDCpNACHsFyl0NERORSGHocSChOAwDUeIQDgiBzNURERK6FocdBRFGEtlyao0fgri0iIiKHY+hxkPzyGoRYpDl6NJyjh4iIyOEYehwko8iA7rVz9Cj9GXqIiIgcjaHHQTKLKhHBw9WJiIhk4xShZ+XKlYiMjISbmxtGjx6N/fv3t+lx69atgyAImDJlin0LtIFGc/RwTA8REZHDyR561q9fj8TERCxevBiHDx9GdHQ04uLikJub2+rjLl++jGeeeQa33HKLgyrtmJy8AgQIpdIN9vQQERE5nOyhZ/ny5Zg7dy7mzJmDgQMHYtWqVdDr9Vi9enWLjzGbzZg5cyaWLFmCXr16ObDa61eTf0n6qfYCdD7yFkNEROSCVHI+eU1NDQ4dOoSFCxdalykUCowdOxZ79+5t8XFLly5FUFAQHn74Yfz000+tPkd1dTWqq6utt0tLpd4Wo9EIlUplvW53DeboERzxfJ1I3fvvkHagFrEdnAPbwTmwHZxDw3awRVvIGnry8/NhNpsRHNx4duLg4GCcOXOm2cf8/PPP+Oyzz3D06NE2PUdSUhKWLFnSZPnWrVuh1+sBAMnJye0rvJ0sIqCryABUQL5Jj2ObNtn1+Tore7cDtQ3bwTmwHZwD28E5JCcnw2AwdHg7soae9iorK8ODDz6ITz75BAEBAW16zMKFC5GYmGi9XVpaioiICIwfPx46nQ7JyckYN24c1Gq1vcpGTmkVCg/+EwAQFnUDwsZNtNtzdUZGo9Eh7UCtYzs4B7aDc2A7OIeG7VBZWdnh7ckaegICAqBUKpGTk9NoeU5ODkJCQpqsf+HCBVy+fBmTJk2yLrNYLAAAlUqF1NRU9O7du9FjtFottFptk22p1WrrB7nhdXvILitDRO0cPeqA3gB/gZpl73agtmE7OAe2g3NgOzgHtVoNk8nU4e3IOpBZo9EgJiYGKSkp1mUWiwUpKSmIjY1tsv6AAQNw/PhxHD161Hr5/e9/jzvuuANHjx5FRESEI8tvM87RQ0REJD/Zd28lJiYiPj4eI0eOxKhRo7BixQpUVFRgzpw5AIBZs2YhLCwMSUlJcHNzw+DBgxs93sfHBwCaLHcmGQUVuItz9BAREclK9tAzbdo05OXlYdGiRcjOzsawYcOwefNm6+Dm9PR0KBSyH1nfIYX5OfAUavdF+nSXtxgiIiIXJXvoAYCEhAQkJCQ0e9+OHTtafezatWttX5CNGQulOXoqtQHQqXUyV0NEROSaOncXSiehKE4HAJi82MtDREQkF4YeOzNbRLgbMgEASr9IeYshIiJyYQw9dpZdWoUwSIeruwV2jlNmEBERdUUMPXaWWWiwHq6u8OORW0RERHJh6LEzaY6e2jPG+0bKWgsREZErY+ixs4zCcoQJ+dINTkxIREQkG4YeOyvLy4BWMMECJeAVJnc5RERELouhx85MBZcBAJX6UEDpFNMiERERuSSGHjtTlUpz9Ji9OUcPERGRnBh67MhktsCz8goAQO0fKW8xRERELo6hx46ySqoQXnu4upZz9BAREcmKoceOMooM1sPVFTxcnYiISFYMPXaUWVhp7emBLw9XJyIikhNDjx1dLShBKAqlG5yjh4iISFYMPXZkyLsMhSDCqNACHkFyl0NEROTSGHrsyFx4GQBQ5R4OCIK8xRAREbk4hh47UpdlAAAsnKOHiIhIdpwi2E6qTWZ4VV0FVIAmoKfc5RARdSpmsxlGo1G25zcajVCpVKiqqoLZbJatDlej0WigUNivP4ahx06yiqush6u7BTL0EBG1hSiKyM7ORnFxsex1hISEICMjAwKHJziMQqFAz549odFo7LJ9hh47ySyqRETt4eoC5+ghImqTusATFBQEvV4vW+CwWCwoLy+Hh4eHXXseqJ7FYsHVq1eRlZWF7t2726XtGXrsJKPIgHGco4eIqM3MZrM18Pj7+8tai8ViQU1NDdzc3Bh6HCgwMBBXr16FyWSCWq22+fbZknaSk5+PAKFUusGeHiKi31Q3hkev18tcCcmlbreWvcZRMfTYSWXuJQBAlcoLcPOWuRoios6DY2hcl73bnqHHXoouAwCqPcLlrYOIiIgAMPTYjaZ2jh6Rp58gIqJ2iIyMxIoVK9q8/o4dOyAIguxHvHUGDD12UGU0w7cmCwDgFthL5mqIiMiebr/9djz11FM2296BAwfw6KOPtnn9MWPGICsrC97ezj2Uwtbv0/Xg0Vt2cKW4/nB1LefoISJyeaIowmw2Q6X67a/dwMDAdm1bo9EgJCTkektzKezpsYOMQgPCaycm5Bw9RETXRxRFGGpMslxEUWxTjbNnz8bOnTvx7rvvQhAECIKAy5cvW3c5/e9//0NMTAy0Wi1+/vlnXLhwAZMnT0ZwcDA8PDxwww034Mcff2y0zWt3bwmCgE8//RRTp06FXq9H37598f3331vvv3b31tq1a+Hj44MtW7YgKioKHh4emDBhArKysqyPMZlMePLJJ+Hj4wN/f388//zziI+Px5QpU1p8rWlpaZg0aRJ8fX3h7u6OQYMGYdOmTdb7T5w4gbvvvhseHh4IDg7Ggw8+iPz8/FbfJ0djT48dZBYaMLJujh6O6SEiui6VRjMGLtoiy3OfeHlcm9Z79913cfbsWQwePBhLly4FIPXU1H2hL1iwAG+99RZ69eoFX19fZGRkYOLEiXj11Veh1Wrx+eefY9KkSUhNTUX37i2fp3HJkiV444038Oabb+L999/HzJkzkZaWBj8/v2bXNxgMeOutt/DFF19AoVDggQcewDPPPIMvv/wSAPD666/jyy+/xJo1axAVFYV3330X3377Le64444Wa5g3bx5qamqwa9cuuLu749SpU/Dw8AAAFBcX484778QjjzyCd955B5WVlXj++edx//33Y9u2bS2+T47G0GMHBXnZ8BCqpBs+PNkoEVFX5e3tDY1GA71e3+wupqVLl2LcuPoA5efnh+joaOvtV155Bd988w2+//57JCQktPg8s2fPxvTp0wEAy5Ytw3vvvYf9+/djwoQJza5vNBqxatUq9O7dGwCQkJBgDRsA8P7772PhwoWYOnUqAOCDDz5o1GvTnPT0dNx3330YMmQIAKBXr/oxqx988AGGDx+OZcuWWZetXr0aEREROHv2LPr169fq++QoDD12UJV/EQBQoQmAu9pN5mqIiDonnVqJU0vjZHlurVJAWVXHtzNy5MhGt8vLy/Hyyy9j48aNyMrKgslkQmVlJdLT01vdztChQ63X3d3d4eXlhdzc3BbX1+v11sADAKGhodb1S0pKkJOTg1GjRlnvVyqViImJgcViaXGbTz75JB5//HFs3boVY8eOxX333Wet69ixY9i+fbu156ehCxcuoF+/fq2+Pkdh6LEDoSgNAFDjGQF3mWshIuqsBEGAXiPP11RrX/7t4e7e+FvgmWeeQXJyMt566y306dMHOp0Of/jDH1BTU9Pqdq49JYMgCK3W2Nz6bR2n1JJHHnkEcXFx2LhxI7Zu3YqkpCS8/fbb+POf/4zy8nJMmjQJr7/+epPHhYaGduh5bYkDme3ArVyao4eDmImIuj6NRtPm0ybs3r0bs2fPxtSpUzFkyBCEhIQ4fECvt7c3goODceDAAesys9mMw4cP/+ZjIyIi8Nhjj2HDhg34y1/+gk8++QQAMGLECJw8eRKRkZHo06dPo0td8GvP+2QvDD02Zqgxwd+YDYBz9BARuYLIyEjs27cPly9fRn5+fqs9MH379sWGDRtw9OhRHDt2DDNmzLBZr1J7/PnPf0ZSUhK+++47pKamYv78+SgqKmr1NBBPPfUUtmzZgkuXLuHw4cPYvn07oqKiAEiDnAsLCzF9+nQcOHAAFy5cwJYtWzBnzhxr0GnP+2QvDD02dqWoEhG1h6u7cY4eIqIu75lnnoFSqcTAgQMRGBjY6vic5cuXw9fXF2PGjMGkSZMQFxeHESNGOLBayfPPP4/p06dj1qxZiI2NhYeHB+Li4uDm1vI4VLPZjHnz5iEqKgoTJkxAv3798Le//Q0A0K1bN+zevRtmsxnjx4/HkCFD8NRTT8HHx8d6lvr2vE/2wjE9NpZRZEBk3eHqvjxcnYioq+vXrx/27t3baFlkZGSzY2giIyOxbdu2RsvmzZvX6Pa1u7ua207DU07cfvvtjdaZPXs2Zs+e3Wj9KVOmNFpHpVLh/fffx/vvvw9AGsMUFRWF+++/v+kLrFW3bkvqerFa0tz75GgMPTaWWViBmwRpMibO0UNERM4oLS0NW7duxW233Ybq6mp88MEHuHTpEmbMmCF3aXbF3Vs2VpyTDq1ggllQAl5hcpdDRETUhEKhwNq1a3HDDTfgpptuwvHjx/Hjjz9ax+h0VezpsTFj/iUAQIVbKLyUfHuJiMj5REREYPfu3XKX4XDs6bExRbE0R4/RM0LmSoiIiKghhh4b01VkAgCUfpHyFkJERESNOEXoWblyJSIjI+Hm5obRo0dj//79La67YcMGjBw5Ej4+PnB3d8ewYcPwxRdfOLDalpVVGRFolubo0QVzjh4iIiJnInvoWb9+PRITE7F48WIcPnwY0dHRiIuLa/GcIn5+fnjhhRewd+9e/Prrr5gzZw7mzJmDLVvkORNvQ5lFlQivPVxdG8DQQ0RE5ExkDz3Lly/H3LlzMWfOHAwcOBCrVq2CXq/H6tWrm13/9ttvx9SpUxEVFYXevXtj/vz5GDp0KH7++WcHV95UZoOJCXm4OhERkXOR9fCimpoaHDp0CAsXLrQuUygUGDt2bJsmMBJFEdu2bUNqamqzJzkDgOrqalRXV1tvl5aWAgCMRiNUKpX1ui1k5BbgLhRJ2/ToBthou11d3ftvq3ag68N2cA6u3A5GoxGiKMJischyioKG6ibyq6uHHMNisUAURRiNRiiVyka/D7b4nZA19OTn58NsNiM4OLjR8uDgYJw5c6bFx5WUlCAsLAzV1dVQKpX429/+hnHjxjW7blJSEpYsWdJk+datW6HX6wEAycnJHXgV9c5cyIVCEFENLTbvPAC0cg4TaspW7UAdw3ZwDq7YDiqVCiEhISgvL//Ns447SllZmdwluJSamhpUVlZi165dMJlM1uXJyckwGAwd3n6nnEjG09MTR48eRXl5OVJSUpCYmIhevXrh9ttvb7LuwoULkZiYaL1dWlqKiIgIjB8/HjqdDsnJyRg3bhzUanWH67r46adAKWBwD8PEe+7p8PZchdFotGk70PVhOzgHV26HqqoqZGRkwMPDo9VzQDmCKIooKyuDp6dnqyfhBIA777wT0dHReOedd2z2/HPmzEFxcTG++eYbm23zWpcvX0bv3r1x6NAhDBs2zG7P0x5VVVXQ6XS49dZb4ebm1uj3obKyssPblzX0BAQEQKlUIicnp9HynJwchISEtPg4hUKBPn36AACGDRuG06dPIykpqdnQo9VqodVqmyxXq9XW/1AaXu8IZVkGAMDs3d3l/rOyBVu1A3UM28E5uGI7mM1mCIIAhUJhPUmlXOp2adXV81vaul5bCYJg821eq27bzvB+11EoFBAEocnnX61WN+r5ue7td3gLHaDRaBATE4OUlBTrMovFgpSUFMTGxrZ5OxaLpdG4Hbm4G6Q5elSco4eIqONEEaipkOfSzEk+mzN79mzs3LkT7777rjWo1J0w9MSJE7j77rvh4eGB4OBgPPjgg8jPz7c+9uuvv8aQIUOg0+ng7++PsWPHoqKiAi+//DL+/ve/47vvvrNuc8eOHc0+f0vbqPPpp58iKioKbm5uGDBggPWs6ADQs2dPAMDw4cMhCEKzHQddjey7txITExEfH4+RI0di1KhRWLFiBSoqKjBnzhwAwKxZsxAWFoakpCQA0hidkSNHonfv3qiursamTZvwxRdf4MMPP5TzZaCk0ohgcw6gBNyDe8taCxFRl2A0AMu6yfPcCzLbtNq7776Ls2fPYvDgwVi6dCkAIDAwEMXFxbjzzjvxyCOP4J133kFlZSWef/553H///di2bRuysrIwffp0vPHGG5g6dSrKysrw008/QRRFPPPMMzh9+jRKS0uxZs0aANJ0LddqbRsA8OWXX2LRokX44IMPMHz4cBw5cgRz586Fu7s74uPjsX//fowaNQo//vgjBg0aBI1GY6M3z3nJHnqmTZuGvLw8LFq0CNnZ2Rg2bBg2b95sHdycnp7eqNutoqICTzzxBDIzM6HT6TBgwAD84x//wLRp0+R6CQCAjEIDwmsPV1cH9JS1FiIicgxvb29oNBro9fpGwzLqgsayZcusy1avXo2IiAicPXsW5eXlMJlMuPfee9GjhzTFyZAhQ6zr6nQ6VFdXtzrUIysrq9VtLF68GG+//TbuvfdeAFLPzqlTp/DRRx8hPj4egYGBAAB/f/9Wn6crkT30AEBCQgISEhKave/aLr2//vWv+Otf/+qAqtqnxmxBb2U+IIJz9BAR2YJaD/zfVXmeW+kGVF3/kVvHjh3D9u3b4eHh0eS+CxcuYPz48bjrrrswZMgQxMXFYfz48fjDH/4AX1/fNj9HdHR0i9uoqKjAhQsX8PDDD2Pu3LnWx5hMJnh7e1/36+rsnCL0dAUjgtWAKM0BBF+GHiKiDhMEQOMuz3N3cG6e8vJyTJo0qdk55EJDQ6FUKpGcnIw9e/Zg69ateP/99/HCCy9g37591rE2v6W1bdRNyfLJJ59g9OjRTR7nqpxjuHZXUHt2dbj5AG6um6KJiFyNRqOB2WxutGzEiBE4efIkIiMj0adPn0YXd3cpyAmCgJtuuglLlizBkSNHoNForIeoN7fN5rS0jeDgYHTr1g0XL15s8vx1oapuDE9bnqerYE+PrRgKpcDjGyl3JURE5ECRkZHYt28fLl++DA8PD/j5+WHevHn45JNPMH36dDz33HPw8/PD+fPnsW7dOnz66ac4ePAgUlJSMH78eAQFBWHfvn3Iy8tDVFSUdZtbtmxBamoq/P394e3t3WQKg3379rW6jSVLluDJJ5+Et7c3JkyYgOrqahw8eBBFRUVITExEUFAQdDodNm/ejPDwcLi5uXX5XV/s6bGVnrcAC9KAhzbLXQkRETnQM888A6VSiYEDByIwMBDp6eno1q0bdu/eDbPZjPHjx2PIkCF46qmn4OPjA4VCAS8vL+zatQsTJ05Ev3798OKLL+Ltt9/G3XffDQCYO3cu+vfvj5EjRyIwMBC7d+9u8ry/tY1HHnkEn376KdasWYMhQ4bgtttuw9q1a609PSqVCu+99x4++ugjdOvWDZMnT3bcmyYT9vTYmlondwVERORA/fr1a/Z8kX379sWGDRuafUxUVBQ2b275j+TAwEBs3bq11ef9rW0AwIwZMzBjxowW73/kkUfwyCOPtLqNroQ9PUREROQSGHqIiIjIJTD0EBERkUtg6CEiIiKXwNBDRERORWzjyT6p67F32zP0EBGRU6ibh8ZgMMhcCcmlpqYGgP1mjeYh60RE5BSUSiV8fHyQmyudvFmv10MQBFlqsVgsqKmpQVVVVaOTXpP9WCwW5OXlQa/XQ6WyTzxh6CEiIqdRd7bvuuAjF1EUUVlZCZ1OJ1vwckUKhQLdu3e323vO0ENERE5DEASEhoYiKCgIRqNRtjqMRiN27dqFW2+9tcnpH8h+NBqNXXvWGHqIiMjpKJVKWc8GrlQqYTKZ4ObmxtDThXBHJREREbkEhh4iIiJyCQw9RERE5BJcbkxP3cRHpaWlMBqNMBgMKC0t5T5bGbEdnAPbwTmwHZwD28E5NGyHyspKAB2bwNDlQk9ZWRkAICIiQuZKiIiIqL3Kysrg7e19XY8VRBeb79tiseDq1avw9PREWVkZIiIikJGRAS8vL7lLc1mlpaVsByfAdnAObAfnwHZwDg3boe57u1u3btd9WLvL9fQoFAqEh4cDgHXyIy8vL36onQDbwTmwHZwD28E5sB2cQ107XG8PTx0OZCYiIiKXwNBDRERELsGlQ49Wq8XixYuh1WrlLsWlsR2cA9vBObAdnAPbwTnYuh1cbiAzERERuSaX7ukhIiIi18HQQ0RERC6BoYeIiIhcAkMPERERuQSXDj0rV65EZGQk3NzcMHr0aOzfv1/ukrq0Xbt2YdKkSejWrRsEQcC3337b6H5RFLFo0SKEhoZCp9Nh7NixOHfunDzFdmFJSUm44YYb4OnpiaCgIEyZMgWpqamN1qmqqsK8efPg7+8PDw8P3HfffcjJyZGp4q7pww8/xNChQ62TrsXGxuJ///uf9X62geO99tprEAQBTz31lHUZ28ExXn75ZQiC0OgyYMAA6/22ageXDT3r169HYmIiFi9ejMOHDyM6OhpxcXHIzc2Vu7Quq6KiAtHR0Vi5cmWz97/xxht47733sGrVKuzbtw/u7u6Ii4tDVVWVgyvt2nbu3Il58+bhl19+QXJyMoxGI8aPH4+KigrrOk8//TR++OEH/Pvf/8bOnTtx9epV3HvvvTJW3fWEh4fjtddew6FDh3Dw4EHceeedmDx5Mk6ePAmAbeBoBw4cwEcffYShQ4c2Ws52cJxBgwYhKyvLevn555+t99msHUQXNWrUKHHevHnW22azWezWrZuYlJQkY1WuA4D4zTffWG9bLBYxJCREfPPNN63LiouLRa1WK/7zn/+UoULXkZubKwIQd+7cKYqi9L6r1Wrx3//+t3Wd06dPiwDEvXv3ylWmS/D19RU//fRTtoGDlZWViX379hWTk5PF2267TZw/f74oivxdcKTFixeL0dHRzd5ny3ZwyZ6empoaHDp0CGPHjrUuUygUGDt2LPbu3StjZa7r0qVLyM7ObtQm3t7eGD16NNvEzkpKSgAAfn5+AIBDhw7BaDQ2aosBAwage/fubAs7MZvNWLduHSoqKhAbG8s2cLB58+bhnnvuafR+A/xdcLRz586hW7du6NWrF2bOnIn09HQAtm0HlzvhKADk5+fDbDYjODi40fLg4GCcOXNGpqpcW3Z2NgA02yZ195HtWSwWPPXUU7jpppswePBgAFJbaDQa+Pj4NFqXbWF7x48fR2xsLKqqquDh4YFvvvkGAwcOxNGjR9kGDrJu3TocPnwYBw4caHIffxccZ/To0Vi7di369++PrKwsLFmyBLfccgtOnDhh03ZwydBDRJJ58+bhxIkTjfadk+P0798fR48eRUlJCb7++mvEx8dj586dcpflMjIyMjB//nwkJyfDzc1N7nJc2t133229PnToUIwePRo9evTAv/71L+h0Ops9j0vu3goICIBSqWwy8jsnJwchISEyVeXa6t53tonjJCQk4L///S+2b9+O8PBw6/KQkBDU1NSguLi40fpsC9vTaDTo06cPYmJikJSUhOjoaLz77rtsAwc5dOgQcnNzMWLECKhUKqhUKuzcuRPvvfceVCoVgoOD2Q4y8fHxQb9+/XD+/Hmb/j64ZOjRaDSIiYlBSkqKdZnFYkFKSgpiY2NlrMx19ezZEyEhIY3apLS0FPv27WOb2JgoikhISMA333yDbdu2oWfPno3uj4mJgVqtbtQWqampSE9PZ1vYmcViQXV1NdvAQe666y4cP34cR48etV5GjhyJmTNnWq+zHeRRXl6OCxcuIDQ01La/Dx0YbN2prVu3TtRqteLatWvFU6dOiY8++qjo4+MjZmdny11al1VWViYeOXJEPHLkiAhAXL58uXjkyBExLS1NFEVRfO2110QfHx/xu+++E3/99Vdx8uTJYs+ePcXKykqZK+9aHn/8cdHb21vcsWOHmJWVZb0YDAbrOo899pjYvXt3cdu2beLBgwfF2NhYMTY2Vsaqu54FCxaIO3fuFC9duiT++uuv4oIFC0RBEMStW7eKosg2kEvDo7dEke3gKH/5y1/EHTt2iJcuXRJ3794tjh07VgwICBBzc3NFUbRdO7hs6BFFUXz//ffF7t27ixqNRhw1apT4yy+/yF1Sl7Z9+3YRQJNLfHy8KIrSYesvvfSSGBwcLGq1WvGuu+4SU1NT5S26C2quDQCIa9assa5TWVkpPvHEE6Kvr6+o1+vFqVOnillZWfIV3QU99NBDYo8ePUSNRiMGBgaKd911lzXwiCLbQC7Xhh62g2NMmzZNDA0NFTUajRgWFiZOmzZNPH/+vPV+W7WDIIqiaIOeKCIiIiKn5pJjeoiIiMj1MPQQERGRS2DoISIiIpfA0ENEREQugaGHiIiIXAJDDxEREbkEhh4iIiJyCQw9RERE5BIYeoiIbCAyMhIrVqyQuwwiagVDDxFdt9mzZ0MQBDz22GNN7ps3bx4EQcDs2bPtWsPatWshCAIEQYBSqYSvry9Gjx6NpUuXoqSkxC7P5+PjY/PtEpH9MfQQUYdERERg3bp1qKystC6rqqrCV199he7duzukBi8vL2RlZSEzMxN79uzBo48+is8//xzDhg3D1atXHVIDETk/hh4i6pARI0YgIiICGzZssC7bsGEDunfvjuHDhzdad/Pmzbj55pvh4+MDf39//O53v8OFCxes93/++efw8PDAuXPnrMueeOIJDBgwAAaDocUaBEFASEgIQkNDERUVhYcffhh79uxBeXk5nnvuOet6FosFSUlJ6NmzJ3Q6HaKjo/H1119b79+xYwcEQcDGjRsxdOhQuLm54cYbb8SJEyes98+ZMwclJSXW3qWXX37Z+niDwYCHHnoInp6e6N69Oz7++OP2v6FEZDcMPUTUYQ899BDWrFljvb169WrMmTOnyXoVFRVITEzEwYMHkZKSAoVCgalTp8JisQAAZs2ahYkTJ2LmzJkwmUzYuHEjPv30U3z55ZfQ6/XtqikoKAgzZ87E999/D7PZDABISkrC559/jlWrVuHkyZN4+umn8cADD2Dnzp2NHvvss8/i7bffxoEDBxAYGIhJkybBaDRizJgxWLFihbVnKSsrC88884z1cW+//TZGjhyJI0eO4IknnsDjjz+O1NTUdtVNRHZkuxPDE5GriY+PFydPnizm5uaKWq1WvHz5snj58mXRzc1NzMvLEydPnizGx8e3+Pi8vDwRgHj8+HHrssLCQjE8PFx8/PHHxeDgYPHVV19ttYY1a9aI3t7ezd734YcfigDEnJwcsaqqStTr9eKePXsarfPwww+L06dPF0VRFLdv3y4CENetW2e9v6CgQNTpdOL69etbfb4ePXqIDzzwgPW2xWIRg4KCxA8//LDV+onIcVQyZy4i6gICAwNxzz33YO3atRBFEffccw8CAgKarHfu3DksWrQI+/btQ35+vrWHJz09HYMHDwYA+Pr64rPPPkNcXBzGjBmDBQsWXHddoigCkHZ/nT9/HgaDAePGjWu0Tk1NTZPdcLGxsdbrfn5+6N+/P06fPv2bzzd06FDr9bpdbrm5udddPxHZFkMPEdnEQw89hISEBADAypUrm11n0qRJ6NGjBz755BN069YNFosFgwcPRk1NTaP1du3aBaVSiaysLFRUVMDT0/O6ajp9+jS8vLzg7++PixcvAgA2btyIsLCwRutptdrr2v611Gp1o9uCIFiDHRHJj2N6iMgmJkyYgJqaGhiNRsTFxTW5v6CgAKmpqXjxxRdx1113ISoqCkVFRU3W27NnD15//XX88MMP8PDwsAap9srNzcVXX32FKVOmQKFQYODAgdBqtUhPT0efPn0aXSIiIho99pdffrFeLyoqwtmzZxEVFQUA0Gg01jFCRNS5sKeHiGxCqVRadwEplcom9/v6+sLf3x8ff/wxQkNDkZ6e3mTXVVlZGR588EE8+eSTuPvuuxEeHo4bbrgBkyZNwh/+8IcWn1sURWRnZ0MURRQXF2Pv3r1YtmwZvL298dprrwEAPD098cwzz+Dpp5+GxWLBzTffjJKSEuzevRteXl6Ij4+3bm/p0qXw9/dHcHAwXnjhBQQEBGDKlCkApEkIy8vLkZKSgujoaOj1+nYPsiYiebCnh4hsxsvLC15eXs3ep1AosG7dOhw6dAiDBw/G008/jTfffLPROvPnz4e7uzuWLVsGABgyZAiWLVuGP/3pT7hy5UqLz1taWorQ0FCEhYUhNjYWH330EeLj43HkyBGEhoZa13vllVfw0ksvISkpCVFRUZgwYQI2btyInj17Ntrea6+9hvnz5yMmJgbZ2dn44YcfoNFoAABjxozBY489hmnTpiEwMBBvvPHGdb1XROR4glg30o+IyMXt2LEDd9xxB4qKijjrMlEXxJ4eIiIicgkMPUREROQSuHuLiIiIXAJ7eoiIiMglMPQQERGRS2DoISIiIpfA0ENEREQugaGHiIiIXAJDDxEREbkEhh4iIiJyCQw9RERE5BL+P3EGqr8TKpUzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=best_min_samples_leaf)\n",
    "    model.fit(X_train, y_train_bin)\n",
    "    y_preds_train = model.predict(X_train)\n",
    "    y_preds_test = model.predict(X_test)\n",
    "    f1_scores_train.append(f1_score(y_train_bin, y_preds_train))\n",
    "    f1_scores_test.append(f1_score(y_test_bin, y_preds_test))\n",
    "\n",
    "plt.plot(max_depth_values, f1_scores_train, label='training set')\n",
    "plt.plot(max_depth_values, f1_scores_test, label='test set')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Based on the plot above we can see that the upper bound for the F1 score on the test set stabilizes at approximately 0.78.. We already get almost the best possible results (on the test set) for `max_depth`~18 and increasing `max_depth` does not give us any significant improvements. Thus, we set `max_depth`=18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_final_model_scores(model, validation_set=False):\n",
    "    model.fit(X_train, y_train_bin)\n",
    "\n",
    "    y_preds_test = model.predict(X_test)\n",
    "    test_set_scores_df = get_classification_scores(y_test_bin, y_preds_test).rename(columns={'score': 'test_set'})\n",
    "\n",
    "    if validation_set:\n",
    "        y_preds_val = model.predict(X_val)\n",
    "        validation_set_scores_df = get_classification_scores(y_val_bin, y_preds_val).rename(columns={'score': 'validation_set'})\n",
    "        return pd.merge(test_set_scores_df, validation_set_scores_df, on='metric')\n",
    "    return test_set_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.7692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  test_set\n",
       "0   Accuracy    0.9256\n",
       "1  Precision    0.8108\n",
       "2     Recall    0.7317\n",
       "3   F1 score    0.7692"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_max_depth = 18\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_leaf=best_min_samples_leaf)\n",
    "get_final_model_scores(decision_tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 2.2. Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10.000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>None</td>\n",
       "      <td>0.691137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.010</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>None</td>\n",
       "      <td>0.691137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>None</td>\n",
       "      <td>0.691137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>None</td>\n",
       "      <td>0.691137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>None</td>\n",
       "      <td>0.691137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c           solver penalty        F1\n",
       "57  10.000        newton-cg    None  0.691137\n",
       "20   0.010  newton-cholesky    None  0.691137\n",
       "46   1.000  newton-cholesky    None  0.691137\n",
       "5    0.001        newton-cg    None  0.691137\n",
       "7    0.001  newton-cholesky    None  0.691137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "solver_and_penalty = {'lbfgs': ['l2', None], 'liblinear': ['l1', 'l2'], 'newton-cg': ['l2', None],\n",
    "                      'newton-cholesky': ['l2', None], 'sag': ['l2', None], 'saga': ['l1', 'l2', None]}\n",
    "\n",
    "results = {\"c\": [], \"solver\": [], \"penalty\": [], \"F1\": []}\n",
    "\n",
    "for c in c_values:\n",
    "    for solver in solver_and_penalty.keys():\n",
    "        for penalty in solver_and_penalty[solver]:\n",
    "            model = LogisticRegression(C=c, solver=solver, penalty=penalty)\n",
    "            model.fit(X_train, y_train_bin)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            f1 = f1_score(y_test_bin, y_pred_test)\n",
    "\n",
    "            results['c'].append(c)\n",
    "            results['solver'].append(solver)\n",
    "            results['penalty'].append(penalty)\n",
    "            results['F1'].append(f1)\n",
    "\n",
    "scores_df = pd.DataFrame(results, index=None)\n",
    "scores_df = scores_df.sort_values(by=\"F1\", ascending=False)\n",
    "\n",
    "best_c = scores_df.iloc[0].c # any\n",
    "best_solver = scores_df.iloc[0].solver # newton-cg/newton-cholesky\n",
    "best_penalty = scores_df.iloc[0].penalty # None\n",
    "\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  test_set\n",
       "0   Accuracy    0.8982\n",
       "1  Precision    0.7109\n",
       "2     Recall    0.6725\n",
       "3   F1 score    0.6911"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(C=best_c, solver=best_solver, penalty=best_penalty)\n",
    "get_final_model_scores(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>test_set</th>\n",
       "      <th>validation_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>0.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>0.7892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  test_set  validation_set\n",
       "0   Accuracy    0.9253          0.9280\n",
       "1  Precision    0.7945          0.8204\n",
       "2     Recall    0.7544          0.7603\n",
       "3   F1 score    0.7739          0.7892"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We picked the Decision Tree model because it achieved better results\n",
    "get_final_model_scores(decision_tree_model, validation_set=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
